aggregation_metric:
  type: dynascore
context:
- name: context
  placeholder: Enter context...
  type: string
delta_metrics:
- type: fairness
- type: robustness
goal_message: enter a question and select an answer in the context, such that the
  model is fooled.
input:
- name: question
  placeholder: Enter question...
  type: string
- name: answer
  reference_name: context
  type: context_string_selection
metadata:
  create:
  - display_name: example explanation
    name: example_explanation
    placeholder: Explain why your example is correct...
    type: string
  - display_name: model explanation
    model_wrong_condition: false
    name: model_explanation_right
    placeholder: Explain why you thought the model would make a mistake...
    type: string
  - display_name: model explanation
    model_wrong_condition: true
    name: model_explanation_wrong
    placeholder: Explain why you think the model made a mistake...
    type: string
  validate:
  - name: corrected_answer
    reference_name: context
    type: context_string_selection
    validated_label_condition: incorrect
  - name: target_explanation
    placeholder: Explain why your proposed target is correct...
    type: string
    validated_label_condition: incorrect
  - name: flag_reason
    placeholder: Enter the reason for flagging...
    type: string
    validated_label_condition: flagged
  - name: validator_example_explanation
    placeholder: Explain why the example is correct...
    type: string
    validated_label_condition: correct
  - name: validator_model_explanation
    placeholder: Enter what you think was done to try to trick the model...
    type: string
model_wrong_metric:
  reference_name: answer
  threshold: 0.4
  type: string_f1
output:
- name: answer
- name: conf
  single_prob: true
  type: prob
perf_metric:
  reference_name: answer
  type: squad_f1
